# ChatGPT-HealthPrompt
"ChatGPT-HealthPrompt" (an acronym for "Prompt Engineering for Healthcare Decision Making using ChatGPT as the Large Language Model") serves as an evaluative framework to analyze the efficacy and potential hazards of OpenAI's GPT-3 model within the field of healthcare decision-making, especially in diagnostic contexts.

```
@article{deldjoo2023Explainable,
  author       = {Yashar Deldjoo},
  title        = {Fairness of ChatGPT and the Role Of Explainable-Guided Prompts},
  journal      = {CoRR},
  volume       = {abs/2307.11761},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2307.11761},
  doi          = {10.48550/arXiv.2307.11761},
  eprinttype    = {arXiv},
}
```
</br>

<div align="center">
  <figure>
    <img src="flow_char_new.jpg" width="450"/>
    <figcaption>Flowchart illustrating the conceptual framework of the paper</figcaption>
  </figure>
</div>

</br>

---
### ðŸ“Š **Research Summary: ChatGPT in Healthcare Decision-Making**

ðŸ” **Key Insights**:

1. ðŸ“ˆ ChatGPT initially lags in zero-shot scenarios but gains ground in few-shot scenarios.
2. ðŸ§  Incorporating domain-specific knowledge, such as XGB predictions, substantially boosts performance.
3. âš ï¸ Higher rates of False Positives require careful model design and implementation.

---

ðŸŒŸ **Summary**: 
> Our research dives deep into the role of OpenAI's ChatGPT in healthcare decision-making. While the model starts off trailing traditional ML approaches, it shows remarkable adaptability in few-shot learning scenarios. Domain-specific integration notably elevates its capabilities, at times outperforming classical ML models. However, caution is dueâ€”particularly due to increased rates of False Positives and variability in results.
---



